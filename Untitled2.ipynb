{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc3d885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results - Page 1:\n",
      "https://www.google.com/search?q=\n",
      "site:jo.linkedin.com/in \"PMP\" AND \"Government\"\n",
      "&start=0\n",
      "Search results - Page 2:\n",
      "https://www.google.com/search?q=\n",
      "site:jo.linkedin.com/in \"PMP\" AND \"Government\"\n",
      "&start=10\n",
      "Search results - Page 3:\n",
      "https://www.google.com/search?q=\n",
      "site:jo.linkedin.com/in \"PMP\" AND \"Government\"\n",
      "&start=20\n",
      "Search results - Page 4:\n",
      "https://www.google.com/search?q=\n",
      "site:jo.linkedin.com/in \"PMP\" AND \"Government\"\n",
      "&start=30\n",
      "Search results - Page 5:\n",
      "https://www.google.com/search?q=\n",
      "site:jo.linkedin.com/in \"PMP\" AND \"Government\"\n",
      "&start=40\n",
      "Search results - Page 6:\n",
      "https://www.google.com/search?q=\n",
      "site:jo.linkedin.com/in \"PMP\" AND \"Government\"\n",
      "&start=50\n",
      "Search results - Page 7:\n",
      "https://www.google.com/search?q=\n",
      "site:jo.linkedin.com/in \"PMP\" AND \"Government\"\n",
      "&start=60\n",
      "Search results - Page 8:\n",
      "https://www.google.com/search?q=\n",
      "site:jo.linkedin.com/in \"PMP\" AND \"Government\"\n",
      "&start=70\n",
      "Search results - Page 9:\n",
      "https://www.google.com/search?q=\n",
      "site:jo.linkedin.com/in \"PMP\" AND \"Government\"\n",
      "&start=80\n",
      "Search results - Page 10:\n",
      "https://www.google.com/search?q=\n",
      "site:jo.linkedin.com/in \"PMP\" AND \"Government\"\n",
      "&start=90\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set the search query\n",
    "query = \"\"\"\n",
    "site:jo.linkedin.com/in \"PMP\" AND \"Government\"\n",
    "\"\"\"\n",
    "# Set the number of pages to scrape\n",
    "num_pages = 10\n",
    "\n",
    "# Iterate over each page of search results\n",
    "for page in range(num_pages):\n",
    "    # Calculate the start parameter for pagination\n",
    "    start = page * 10\n",
    "\n",
    "    # Send a request to Google and get the response\n",
    "    url = f\"https://www.google.com/search?q={query}&start={start}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Extract search results\n",
    "    search_results = []\n",
    "    for result in soup.find_all(\"div\", class_=\"g\"):\n",
    "        title = result.find(\"h3\", class_=\"LC20lb DKV0Md\").text if result.find(\"h3\", class_=\"LC20lb DKV0Md\") else None\n",
    "        link = result.find(\"a\")[\"href\"] if result.find(\"a\") else None\n",
    "        description = result.find(\"span\", class_=\"aCOpRe\").text if result.find(\"span\", class_=\"aCOpRe\") else None\n",
    "        search_results.append({\"title\": title, \"link\": link, \"description\": description})\n",
    "\n",
    "    # Print search results for the current page\n",
    "    print(f\"Search results - Page {page + 1}:\")\n",
    "    print(url)\n",
    "    for result in search_results:\n",
    "        print(\"Title:\", result[\"title\"])\n",
    "        print(\"Link:\", result[\"link\"])\n",
    "        print(\"Description:\", result[\"description\"])\n",
    "        print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf964438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter youe qsite:jo.linkedin.com/in \"PMP\" AND \"Government\"\n"
     ]
    }
   ],
   "source": [
    "x = input('enter youe q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60ded1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'site:jo.linkedin.com/in \"PMP\" AND \"Government\"'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb200fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': None,\n",
       " 'link': 'https://jo.linkedin.com/in/ahmad-jabr-pmp%C2%AE%EF%B8%8F-705415140',\n",
       " 'description': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7f91f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set the search query\n",
    "query = \"web scraping with python\"\n",
    "\n",
    "# Send a GET request to Google search results page\n",
    "url = f\"https://www.google.com/search?q={query}\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the response\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "print('f')\n",
    "# Extract search results\n",
    "search_results = soup.find_all('div', class_='g')\n",
    "for result in search_results:\n",
    "    title = result.find('h3').text\n",
    "    link = result.find('a')['href']\n",
    "    snippet = result.find('span', class_='aCOpRe').text\n",
    "    print(\"Title:\", title)\n",
    "    print(\"Link:\", link)\n",
    "    print(\"Snippet:\", snippet)\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f27913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc7939e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "search() got an unexpected keyword argument 'num_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb scraping with python\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Perform the Google search\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(j)\n",
      "\u001b[1;31mTypeError\u001b[0m: search() got an unexpected keyword argument 'num_results'"
     ]
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "\n",
    "# Define the query you want to search\n",
    "query = \"web scraping with python\"\n",
    "\n",
    "# Perform the Google search\n",
    "for j in search(query, num_results=10, lang=\"en\"):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea4cdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google\n",
      "  Downloading google-3.0.0-py2.py3-none-any.whl (45 kB)\n",
      "     -------------------------------------- 45.3/45.3 kB 448.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\abdalrahmanshahrour\\anaconda3\\lib\\site-packages (from google) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\abdalrahmanshahrour\\anaconda3\\lib\\site-packages (from beautifulsoup4->google) (2.3.2.post1)\n",
      "Installing collected packages: google\n",
      "Successfully installed google-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0a342e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Print the URLs of the search results\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mURL: \u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mlink)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "\n",
    "# Define the query you want to search\n",
    "query = \"web scraping with python\"\n",
    "\n",
    "# Perform the Google search\n",
    "search_results = search(query)\n",
    "\n",
    "# Print the URLs of the search results\n",
    "for result in search_results:\n",
    "    print(\"Title: \", result.name)\n",
    "    print(\"URL: \", result.link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8acaecf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object search at 0x000002CC076B77D0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f0e7e91",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1755280053.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[21], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"URL: \", result.link)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "print(\"Title: \", result.name)\n",
    "    print(\"URL: \", result.link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd805fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  https://www.edureka.co/blog/web-scraping-with-python/\n",
      "URL:  https://www.edureka.co/blog/web-scraping-with-python/\n",
      "-----------\n",
      "Title:  https://realpython.com/python-web-scraping-practical-introduction/\n",
      "URL:  https://realpython.com/python-web-scraping-practical-introduction/\n",
      "-----------\n",
      "Title:  https://realpython.com/beautiful-soup-web-scraper-python/\n",
      "URL:  https://realpython.com/beautiful-soup-web-scraper-python/\n",
      "-----------\n",
      "Title:  https://oxylabs.io/blog/python-web-scraping\n",
      "URL:  https://oxylabs.io/blog/python-web-scraping\n",
      "-----------\n",
      "Title:  https://www.geeksforgeeks.org/python-web-scraping-tutorial/\n",
      "URL:  https://www.geeksforgeeks.org/python-web-scraping-tutorial/\n",
      "-----------\n",
      "Title:  https://www.youtube.com/watch?v=XVv6mJpFOb0\n",
      "URL:  https://www.youtube.com/watch?v=XVv6mJpFOb0\n",
      "-----------\n",
      "Title:  https://www.scrapingbee.com/blog/web-scraping-101-with-python/\n",
      "URL:  https://www.scrapingbee.com/blog/web-scraping-101-with-python/\n",
      "-----------\n",
      "Title:  https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-2/\n",
      "URL:  https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-2/\n",
      "-----------\n",
      "Title:  https://www.tutorialspoint.com/python_web_scraping/index.htm\n",
      "URL:  https://www.tutorialspoint.com/python_web_scraping/index.htm\n",
      "-----------\n",
      "Title:  https://www.learndatasci.com/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/\n",
      "URL:  https://www.learndatasci.com/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/\n",
      "-----------\n",
      "Title:  https://www.javatpoint.com/web-scraping-using-python\n",
      "URL:  https://www.javatpoint.com/web-scraping-using-python\n",
      "-----------\n",
      "Title:  https://www.projectpro.io/article/python-libraries-for-web-scraping/625\n",
      "URL:  https://www.projectpro.io/article/python-libraries-for-web-scraping/625\n",
      "-----------\n",
      "Title:  https://www.oreilly.com/library/view/web-scraping-with/9781491985564/\n",
      "URL:  https://www.oreilly.com/library/view/web-scraping-with/9781491985564/\n",
      "-----------\n",
      "Title:  https://www.datacamp.com/courses/web-scraping-with-python\n",
      "URL:  https://www.datacamp.com/courses/web-scraping-with-python\n",
      "-----------\n",
      "Title:  https://www.amazon.com/Web-Scraping-Python-Collecting-Modern/dp/1491985577\n",
      "URL:  https://www.amazon.com/Web-Scraping-Python-Collecting-Modern/dp/1491985577\n",
      "-----------\n",
      "Title:  https://www.amazon.com/Web-Scraping-Python-Collecting-Modern/dp/1491910291\n",
      "URL:  https://www.amazon.com/Web-Scraping-Python-Collecting-Modern/dp/1491910291\n",
      "-----------\n",
      "Title:  https://www.browserstack.com/guide/web-scraping-using-selenium-python\n",
      "URL:  https://www.browserstack.com/guide/web-scraping-using-selenium-python\n",
      "-----------\n",
      "Title:  https://intellipaat.com/blog/tutorial/python-tutorial/python-web-scraping-tutorial/\n",
      "URL:  https://intellipaat.com/blog/tutorial/python-tutorial/python-web-scraping-tutorial/\n",
      "-----------\n",
      "Title:  https://blog.apify.com/web-scraping-python/\n",
      "URL:  https://blog.apify.com/web-scraping-python/\n",
      "-----------\n",
      "Title:  https://www.pluralsight.com/paths/web-scraping-with-python\n",
      "URL:  https://www.pluralsight.com/paths/web-scraping-with-python\n",
      "-----------\n",
      "Title:  https://www.pluralsight.com/guides/advanced-web-scraping-tactics-python-playbook\n",
      "URL:  https://www.pluralsight.com/guides/advanced-web-scraping-tactics-python-playbook\n",
      "-----------\n",
      "Title:  https://www.zenrows.com/blog/web-scraping-python\n",
      "URL:  https://www.zenrows.com/blog/web-scraping-python\n",
      "-----------\n",
      "Title:  https://scrapy.org/\n",
      "URL:  https://scrapy.org/\n",
      "-----------\n",
      "Title:  https://rayobyte.com/blog/python-web-scraping/\n",
      "URL:  https://rayobyte.com/blog/python-web-scraping/\n",
      "-----------\n",
      "Title:  https://www.simplilearn.com/tutorials/python-tutorial/web-scraping-with-python\n",
      "URL:  https://www.simplilearn.com/tutorials/python-tutorial/web-scraping-with-python\n",
      "-----------\n",
      "Title:  https://docs.python-guide.org/scenarios/scrape/\n",
      "URL:  https://docs.python-guide.org/scenarios/scrape/\n",
      "-----------\n",
      "Title:  https://brightdata.com/blog/how-tos/web-scraping-with-python\n",
      "URL:  https://brightdata.com/blog/how-tos/web-scraping-with-python\n",
      "-----------\n",
      "Title:  https://scrape-it.cloud/blog/web-scraping-with-python\n",
      "URL:  https://scrape-it.cloud/blog/web-scraping-with-python\n",
      "-----------\n",
      "Title:  https://www.analyticsvidhya.com/blog/2021/10/a-detailed-guide-on-web-scraping-using-python-framework/\n",
      "URL:  https://www.analyticsvidhya.com/blog/2021/10/a-detailed-guide-on-web-scraping-using-python-framework/\n",
      "-----------\n",
      "Title:  https://www.udemy.com/topic/web-scraping/\n",
      "URL:  https://www.udemy.com/topic/web-scraping/\n",
      "-----------\n",
      "Title:  https://github.com/topics/web-scraping-python\n",
      "URL:  https://github.com/topics/web-scraping-python\n",
      "-----------\n",
      "Title:  https://www.upwork.com/resources/web-scraping-python\n",
      "URL:  https://www.upwork.com/resources/web-scraping-python\n",
      "-----------\n",
      "Title:  https://scrapfly.io/blog/web-scraping-with-python/\n",
      "URL:  https://scrapfly.io/blog/web-scraping-with-python/\n",
      "-----------\n",
      "Title:  https://www.makeuseof.com/best-python-libraries-and-tools-for-web-scraping/\n",
      "URL:  https://www.makeuseof.com/best-python-libraries-and-tools-for-web-scraping/\n",
      "-----------\n",
      "Title:  https://scrapeops.io/web-scraping-playbook/best-web-scraping-books/\n",
      "URL:  https://scrapeops.io/web-scraping-playbook/best-web-scraping-books/\n",
      "-----------\n",
      "Title:  https://testsigma.com/blog/python-selenium-web-scraping/\n",
      "URL:  https://testsigma.com/blog/python-selenium-web-scraping/\n",
      "-----------\n",
      "Title:  https://www.mygreatlearning.com/academy/learn-for-free/courses/web-scraping-with-python\n",
      "URL:  https://www.mygreatlearning.com/academy/learn-for-free/courses/web-scraping-with-python\n",
      "-----------\n",
      "Title:  https://www.digitalocean.com/community/tutorials/how-to-crawl-a-web-page-with-scrapy-and-python-3\n",
      "URL:  https://www.digitalocean.com/community/tutorials/how-to-crawl-a-web-page-with-scrapy-and-python-3\n",
      "-----------\n",
      "Title:  https://www.digitalocean.com/community/tutorials/how-to-scrape-web-pages-with-beautiful-soup-and-python-3\n",
      "URL:  https://www.digitalocean.com/community/tutorials/how-to-scrape-web-pages-with-beautiful-soup-and-python-3\n",
      "-----------\n",
      "Title:  https://www.toptal.com/python/web-scraping-with-python\n",
      "URL:  https://www.toptal.com/python/web-scraping-with-python\n",
      "-----------\n",
      "Title:  https://datasciencedojo.com/blog/ethical-web-scraping-using-python/\n",
      "URL:  https://datasciencedojo.com/blog/ethical-web-scraping-using-python/\n",
      "-----------\n",
      "Title:  https://jovian.com/vipinrathore-cv/python-web-scraping-project-guide\n",
      "URL:  https://jovian.com/vipinrathore-cv/python-web-scraping-project-guide\n",
      "-----------\n",
      "Title:  https://www.numpyninja.com/post/scraping-with-python\n",
      "URL:  https://www.numpyninja.com/post/scraping-with-python\n",
      "-----------\n",
      "Title:  https://monashdatafluency.github.io/python-web-scraping/section-2-HTML-based-scraping/\n",
      "URL:  https://monashdatafluency.github.io/python-web-scraping/section-2-HTML-based-scraping/\n",
      "-----------\n",
      "Title:  https://www.ionos.es/digitalguide/paginas-web/desarrollo-web/web-scraping-con-python/\n",
      "URL:  https://www.ionos.es/digitalguide/paginas-web/desarrollo-web/web-scraping-con-python/\n",
      "-----------\n",
      "Title:  https://hackernoon.com/alternatives-to-web-scraping-with-python\n",
      "URL:  https://hackernoon.com/alternatives-to-web-scraping-with-python\n",
      "-----------\n",
      "Title:  https://www.codecademy.com/learn/learn-web-scraping\n",
      "URL:  https://www.codecademy.com/learn/learn-web-scraping\n",
      "-----------\n",
      "Title:  https://www.kaggle.com/code/shadabhussain/web-scraping-with-python-using-beautiful-soup\n",
      "URL:  https://www.kaggle.com/code/shadabhussain/web-scraping-with-python-using-beautiful-soup\n",
      "-----------\n",
      "Title:  https://www.educative.io/blog/python-web-scraping-tutorial\n",
      "URL:  https://www.educative.io/blog/python-web-scraping-tutorial\n",
      "-----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Perform the Google search\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m search(query, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle: \u001b[39m\u001b[38;5;124m\"\u001b[39m, j)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mURL: \u001b[39m\u001b[38;5;124m\"\u001b[39m, j)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\googlesearch\\__init__.py:305\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(query, tld, lang, tbs, safe, num, start, stop, pause, country, extra_params, user_agent, verify_ssl)\u001b[0m\n\u001b[0;32m    302\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(pause)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# Request the Google Search results page.\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43mget_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_ssl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Parse the response and get every anchored URL.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bs4:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\googlesearch\\__init__.py:174\u001b[0m, in \u001b[0;36mget_page\u001b[1;34m(url, user_agent, verify_ssl)\u001b[0m\n\u001b[0;32m    172\u001b[0m cookie_jar\u001b[38;5;241m.\u001b[39madd_cookie_header(request)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_ssl:\n\u001b[1;32m--> 174\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     context \u001b[38;5;241m=\u001b[39m ssl\u001b[38;5;241m.\u001b[39m_create_unverified_context()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   1280\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1035\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m \n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1447\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1447\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m   1450\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:941\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[0;32m    940\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m--> 941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\socket.py:833\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[0;32m    832\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m--> 833\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m    835\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform the Google search\n",
    "for j in search(query, lang=\"en\"):\n",
    "    print(\"Title: \", j)\n",
    "    print(\"URL: \", j)\n",
    "    print(\"-----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bd14730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object search at 0x000002CC08C2B1B0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(query, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ff4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
